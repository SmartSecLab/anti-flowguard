{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CICDoS2019 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "data_dir = 'data'\n",
    "csv_files = glob.glob(os.path.join(data_dir, '**', '*.csv'), recursive=True)\n",
    "\n",
    "# check if 'data/combined_df.csv' exists\n",
    "combined_csv = 'data/combined_data.csv'\n",
    "\n",
    "if os.path.exists(combined_csv):\n",
    "    print(f\"Loading existing {combined_csv}\")\n",
    "    combined_df = pd.read_csv(combined_csv)\n",
    "else:\n",
    "    print(f\"Creating {combined_csv }\")\n",
    "    # for data_file in csv_files[:1]: # for testing\n",
    "    for data_file in csv_files:\n",
    "        print(\"Loading dataset:\", data_file)\n",
    "        df = pd.read_csv(data_file, low_memory=False)\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        # df.drop(columns=['Timestamp', 'Flow ID', 'SimillarHTTP'], inplace=True)\n",
    "        # df.drop(columns=['Timestamp', 'SimillarHTTP'], inplace=True)\n",
    "\n",
    "        # Encode labels as binary (benign or not)\n",
    "        df['Label'] = df['Label'].apply(lambda x: 1 if x == 'BENIGN' else 0)\n",
    "        dfs.append(df)\n",
    "\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    combined_df.to_csv(combined_csv , index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "combined_df['Source IP'] = label_encoder.fit_transform(combined_df['Source IP'])\n",
    "combined_df['Destination IP'] = label_encoder.fit_transform(combined_df['Destination IP'])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = combined_df.drop(columns=['Label'])\n",
    "y = combined_df['Label']\n",
    "\n",
    "# Replace infinite or very large values with NaN\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Impute NaN values with the mean of each feature\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features used in FlowGuard\n",
    "\n",
    "selected_features = [\n",
    "    'Source IP', 'Source Port', 'Destination IP', 'Destination Port',\n",
    "    'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
    "    'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "    'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
    "    'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
    "    'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
    "    'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
    "    'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
    "    'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
    "    'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
    "    'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
    "    'Bwd Header Length'\n",
    "]\n",
    "\n",
    "X = X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(predictions, threshold=0.5):\n",
    "    return [1 if pred >= threshold else 0 for pred in predictions]\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_class = classify(y_pred)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred_class))\n",
    "\n",
    "def evaluate_classifier(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train classifiers\n",
    "classifiers = {\n",
    "    \"ID3 Classifier\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes Classifier\": GaussianNB(),\n",
    "    # \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "}\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    print(\"Training\", name, \"...\")\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # evaluate_classifier(classifier, X_test, y_test)\n",
    "    # Evaluate Linear Regression model for classification\n",
    "    evaluate_model(linear_reg_model, X_test, y_test)\n",
    "    print('-----------------------------------\\n')\n",
    "\n",
    "    # Save the model\n",
    "    # dump(classifier, f'{name}_combined_model.joblib')\n",
    "    # print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming you have your dataset loaded into a DataFrame called 'data'\n",
    "# # Separate features and target variable\n",
    "# X = data.drop(columns=['target_column'])\n",
    "# y = data['target_column']\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to the data\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "sorted_feature_names = [feature_names[i] for i in indices]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), sorted_feature_names, rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ML on the datasete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# # Assuming you have your data loaded into a pandas DataFrame called 'data'\n",
    "# # with the selected features and labels\n",
    "# selected_features = [\n",
    "#     'Source IP', 'Source Port', 'Destination IP', 'Destination Port',\n",
    "#     'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
    "#     'Total Length of Fwd Packets', 'Total Length of Bwd Packets',\n",
    "#     'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
    "#     'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
    "#     'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
    "#     'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
    "#     'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
    "#     'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
    "#     'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
    "#     'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n",
    "#     'Bwd Header Length'\n",
    "# ]\n",
    "\n",
    "# # Splitting data into features and labels\n",
    "# X = data[selected_features].values\n",
    "# y = data['Label'].values\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshaping features for LSTM input (assuming a 3D input shape)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Building the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
